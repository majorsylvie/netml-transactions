# netml

`netml` is a network anomaly detection tool & library written in Python.

The library contains two primary submodules:

* `pparser`: pcap parser\
Parse pcaps to produce flow features using [Scapy](https://scapy.net/).\
(Additional functionality to map pcaps to pandas DataFrames.)

* `ndm`: novelty detection modeling\
Detect novelties / anomalies, via different models, such as OCSVM.

The tool's command-line interface is documented by its built-in help flags such as `-h` and `--help`:

    netml --help


## Installation

The `netml` library is available on [PyPI](https://pypi.org/project/netml/):

    pip install netml

Or, from a repository clone:

    pip install .

### CLI

The CLI tool is available as a distribution "extra":

    pip install netml[cli]

Or:

    pip install .[cli]

#### Tab-completion

Shell tab-completion is provided by [`argcomplete`](https://github.com/kislyuk/argcomplete) (through `argcmdr`). Completion code appropriate to your shell may be generated by `register-python-argcomplete`, _e.g._:

    register-python-argcomplete --shell=bash netml

The results of the above should be evaluated, _e.g._:

    eval "$(register-python-argcomplete --shell=bash netml)"

Or, to ensure the above is evaluated for every session, _e.g._:

    register-python-argcomplete --shell=bash netml > ~/.bash_completion

For more information, refer to `argcmdr`: [Shell completion](https://github.com/dssg/argcmdr/tree/0.6.0#shell-completion).


## Use

### Simple data manipulation

#### Packet captures to pandas DataFrames

```python
from netml.pparser.parser import PCAP

pcap = PCAP('data/demo.pcap')

pcap.pcap2pandas()

pdf = pcap.df
```

#### Packet captures to flow-based features

```python
from netml.pparser.parser import PCAP
from netml.utils.tool import dump_data, load_data

pcap = PCAP('data/demo.pcap', flow_ptks_thres=2)

pcap.pcap2flows()

# Extract inter-arrival time features
pcap.flow2features('IAT', fft=False, header=False)

iat_features = pcap.features
```

Possible features to pass to `flows2features` include:

* `IAT`: A flow is represented as a timeseries of inter-arrival times between
  packets, *i.e.*, elapsed time in seconds between any two packets in the flow.

* `STATS`: A flow is represented as a set of statistical quantities. We choose
  12 of the most common such statistics in the literature: flow duration, number of
  packets sent per second, number of bytes per second, and various statistics on
  packet sizes within each flow: mean, standard deviation, inter-quartile range,
  minimum, and maximum. Finally, the total number of packets and total number
  of bytes for each flow.

* `SIZE`: A flow is represented as a timeseries of packet sizes in bytes, with one
  sample per packet.

* `SAMP_NUM`: A flow is partitioned into small intervals of equal length ùõøùë°, and
  the number of packets in each interval is recorded; thus, a flow is
  represented as a timeseries of packet counts in small time intervals, with one
  sample per time interval. Here, ùõøùë° might be viewed as a choice of sampling
  rate for the timeseries, hence the nomenclature.

* `SAMP_SIZE`: A flow is partitioned into time intervals of equal length ùõøùë°, and
  the total packet size (*i.e.*, byte count) in each interval is recorded; thus, a
  flow is represented as a timeseries of byte counts in small time intervals,
  with one sample per time interval.

### Manipulating DNS Traffic
NetML offers some functionality targetted specifically for DNS traffic.
#### pcap.pcap2pandas()
This is primarily seen in the information made available through `pcap.pcap2pandas()`.

```py
pcap = PCAP("relative/or/absolute/path/to/some/data.pcap")
pcap.pcap2pandas()
packet_capture_dataframe = pcap.df
```
The above produced dataframe will have the following columns: *(All columns targetted towards DNS traffic have `dns` in their names)*
- datetime
- *dns_query*
- *dns_record_qtype*
- *dns_resp*
- *dns_transaction_id*
- ip_dst
- ip_dst_int
- ip_src
- ip_src_int
- *is_dns*
- length
- mac_dst
- mac_dst_int
- mac_src
- mac_src_int
- port_dst
- port_src
- protocol
- time
- time_normed

where `dns_query` and `dns_resp` contains the query and response information in plain text.
`is_dns` is a boolean that is True for DNS traffic and False otherwise
`dns_transaction_id` is the transaction id for a DNS packet, stored as an unsigned 16 bit integer (pandas dtype UInt16)
`dns_record_qtype` is the string representation of a DNS packet's record type. The mapping between question type numbers and strings are provided by IANA: https://www.iana.org/assignments/dns-parameters/dns-parameters.xhtml and programmatically determined through the helper functions  `_dns_record_qtype_to_string()` and `_match_dns_record_to_range()` in `src/netml/pparser/parser.py`.

All of the DNS related information can only ever by present for DNS packets. And are set to null values for any non-DNS traffic. `dns_resp` for example is null for any DNS requests, while `dns_transaction_id` should be present for *all* DNS traffic.

*Note about null values for DNS record type*
The question of including the record type (A, AAAA, CNAME, ...) in a DNS response is left up to the DNS resolver.
Some DNS resolvers do include them, some don't.
Thus sometimes you may work with data that has DNS record types on all DNS packet.
Other times you may encounter data that only has DNS records on the requests.

*Note of nuance about multiple records in one query:*
it is technically allowed (via RFC 1035) for DNS packets to have more than one question/record in one query (refer to the `QDCOUNT` portion of the DNS structure in section 4.1.1 and 4.1.2 in RFC 1035: https://www.rfc-editor.org/rfc/rfc1035).
However, in practice this is apparently not done, mainly because of the difficulty and ambiguity that comes from multiple questions and record types (like what does the `RCODE` mean with two questions?).
**Thus, the implementation for adding the `dns_record_qtype` column assumes that there will be only one record per packet.**

#### Easily Filter for DNS traffic
Along with having the `is_dns` column in `pcap.pcap2pandas()`, we've also provided the `pcap.df.dns_traffic` property, which will return only the DNS traffic from a particular `PCAP`'s dataframe.

Letting you do:

```py
pcap = PCAP("relative/or/absolute/path/to/some/data.pcap")
pcap.pcap2pandas()
only_dns_traffic_df =  pcap.df.dns_traffic
```

Though it still is possible to use `is_dns`, especially useful if you want to exclude DNS traffic or 
filter for DNS traffic after doing other operation to the dataframe.

```py
pcap_df = pcap.df
...
only_dns_traffic_df = pcap_df[pcap_df["is_dns"]]
```

### Classification of network traffic for outlier detection

Having [trained a model](#training-a-network-traffic-model) to your network traffic,
the identification of anomalous traffic is as simple as providing a packet capture (PCAP)
file to the `netml classify` command of the CLI:

    netml classify --model=model.dat < unclassified.pcap

Using the Python library, the same might be accomplished, _e.g._:

```python
from netml.pparser.parser import PCAP
from netml.utils.tool import load_data

pcap = PCAP(
    'unclassified.pcap',
    flow_ptks_thres=2,
    random_state=42,
    verbose=10,
)

# extract flows from pcap
pcap.pcap2flows(q_interval=0.9)

# extract features from each flow given feat_type
pcap.flow2features('IAT', fft=False, header=False)

(model, train_history) = load_data('model.dat')

model.predict(pcap.features)
```

### Training a network traffic model

A model may be trained for outlier detection as simply as providing a PCAP file to the `netml learn` command:

    netml learn --pcap=traffic.pcap \
                --output=model.dat

(Note that for clarity and consistency with the `classify` command, the flags `--output` and `--model` are synonymous to the `learn` command.)

`netml learn` supports a great many additional options, documented by `netml learn --help`, `--help-algorithm` and `--help-param`, including:

* `--algorithm`: selection of model-training algorithms, such as One-Class Support Vector Machine (OCSVM), Kernel Density Estimation (KDE), Isolation Forest (IF) and Autoencoder (AE)
* `--param`: customization of model hyperparameters via YAML/JSON
* `--label`, `--pcap-normal` & `--pcap-abnormal`: optional labeling of traffic to enable post-training testing of the model

In the below examples, an OCSVM model is trained by demo traffic included in the library, and tested by labels in a CSV file, (both provided by the University of New Brunswick's [Intrusion Detection Systems dataset](https://www.unb.ca/cic/datasets/ids-2017.html)).

All of the below may be wrapped up into a single command via the CLI:

    netml learn --pcap=data/demo.pcap           \
                --label=data/demo.csv           \
                --output=out/OCSVM-results.dat

#### PCAP to features

To only extract features via the CLI:

    netml learn extract                         \
                --pcap=data/demo.pcap           \
                --label=data/demo.csv           \
                --feature=out/IAT-features.dat

Or in Python:

```python
from netml.pparser.parser import PCAP
from netml.utils.tool import dump_data

pcap = PCAP(
    'data/demo.pcap',
    flow_ptks_thres=2,
    random_state=42,
    verbose=10,
)

# extract flows from pcap
pcap.pcap2flows(q_interval=0.9)

# label each flow (optional)
pcap.label_flows(label_file='data/demo.csv')

# extract features from each flow via IAT
pcap.flow2features('IAT', fft=False, header=False)

# dump data to disk
dump_data((pcap.features, pcap.labels), out_file='out/IAT-features.dat')

# stats
print(pcap.features.shape, pcap.pcap2flows.tot_time, pcap.flow2features.tot_time)
```

#### Features to model

To train from already-extracted features via the CLI:

    netml learn train                           \
                --feature=out/IAT-features.dat  \
                --output=out/OCSVM-results.dat

Or in Python:

```python
from sklearn.model_selection import train_test_split

from netml.ndm.model import MODEL
from netml.ndm.ocsvm import OCSVM
from netml.utils.tool import dump_data, load_data

RANDOM_STATE = 42

# load data
(features, labels) = load_data('out/IAT-features.dat')

# split train and test sets
(
    features_train,
    features_test,
    labels_train,
    labels_test,
) = train_test_split(features, labels, test_size=0.33, random_state=RANDOM_STATE)

# create detection model
ocsvm = OCSVM(kernel='rbf', nu=0.5, random_state=RANDOM_STATE)
ocsvm.name = 'OCSVM'
ndm = MODEL(ocsvm, score_metric='auc', verbose=10, random_state=RANDOM_STATE)

# train the model from the train set
ndm.train(features_train)

# evaluate the trained model
ndm.test(features_test, labels_test)

# dump data to disk
dump_data((ocsvm, ndm.history), out_file='out/OCSVM-results.dat')

# stats
print(ndm.train.tot_time, ndm.test.tot_time, ndm.score)
```

For more examples, see the `examples/` directory in the source repository.


## Architecture

- `examples/`\
example code and datasets
- `src/netml/ndm/`\
detection models (such as OCSVM)
- `src/netml/pparser/`\
pcap processing (feature extraction) 
- `src/netml/utils/`\
common functions (such as `load_data` and `dump_data`)
- `tests/`\
test cases
- `LICENSE.txt`
- `manage.py`\
library development & management module
- `README.md`
- `setup.cfg`
- `setup.py`
- `tox.ini`


## To Do

Further work includes:

- Evaluate `pparser` performance on different pcaps
- Add test cases
- Add examples
- Add (generated) docs

We welcome any comments to make this tool more robust and easier to use!


## Development

Development dependencies may be installed via the `dev` extras (below assuming a source checkout):

    pip install --editable .[dev]

(Note: the installation flag `--editable` is also used above to instruct `pip` to place the source checkout directory itself onto the Python path, to ensure that any changes to the source are reflected in Python imports.)

Development tasks are then managed via [`argcmdr`](https://github.com/dssg/argcmdr) sub-commands of `manage ‚Ä¶`, (as defined by the repository module `manage.py`), _e.g._:

    manage version patch -m "initial release of netml" \
           --build                                     \
           --release


## Acknowledgments

`netml` is based on the initial work of the ["Outlier Detection" library `odet`](https://github.com/Learn-Live/odet) üôå

This work was authored by Kun Yang under the direction of Professor Samory
Kpotufe at Columbia University.


## Citation

    @article{yang2020comparative,
             title={A Comparative Study of Network Traffic Representations for Novelty Detection},
             author={Kun Yang and Samory Kpotufe and Nick Feamster},
             year={2020},
             eprint={2006.16993},
             archivePrefix={arXiv},
             primaryClass={cs.NI}
    }
